{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from bytetracker import BYTETracker\n",
    "from bytetracker.basetrack import BaseTrack\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.bbox.utils import rescale_bbox, xy_center_to_xyxy\n",
    "from lib.sequence import Sequence\n",
    "from trackreid.args.reid_args import OUTPUT_POSITIONS\n",
    "from trackreid.reid_processor import ReidProcessor\n",
    "\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real life data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "DETECTION_PATH = f\"{DATA_PATH}/detections\"\n",
    "FRAME_PATH = f\"{DATA_PATH}/frames\"\n",
    "VIDEO_OUTPUT_PATH = \"private\"\n",
    "\n",
    "SEQUENCES = os.listdir(DETECTION_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_frames(sequence):\n",
    "    frames = os.listdir(f\"{FRAME_PATH}/{sequence}\")\n",
    "    frames = [os.path.join(f\"{FRAME_PATH}/{sequence}\", frame) for frame in frames]\n",
    "    frames.sort()\n",
    "    return frames\n",
    "\n",
    "def get_sequence_detections(sequence):\n",
    "    detections = os.listdir(f\"{DETECTION_PATH}/{sequence}\")\n",
    "    detections = [os.path.join(f\"{DETECTION_PATH}/{sequence}\", detection) for detection in detections]\n",
    "    detections.sort()\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHandler():\n",
    "    def __init__(self, image_shape) -> None:\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "    def process(self, detection_output):\n",
    "        if detection_output.size:\n",
    "            if detection_output.ndim == 1:\n",
    "                detection_output = np.expand_dims(detection_output, 0)\n",
    "\n",
    "            processed_detection = np.zeros(detection_output.shape)\n",
    "\n",
    "            for idx, detection in enumerate(detection_output):\n",
    "                clss = detection[0]\n",
    "                conf = detection[5]\n",
    "                bbox = detection[1:5]\n",
    "                xyxy_bbox = xy_center_to_xyxy(bbox)\n",
    "                rescaled_bbox = rescale_bbox(xyxy_bbox,self.image_shape)\n",
    "                processed_detection[idx,:4] = rescaled_bbox\n",
    "                processed_detection[idx,4] = conf\n",
    "                processed_detection[idx,5] = clss\n",
    "\n",
    "            return processed_detection\n",
    "        else:\n",
    "            return detection_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingHandler():\n",
    "    def __init__(self, tracker) -> None:\n",
    "        self.tracker = tracker\n",
    "\n",
    "    def update(self, detection_outputs, frame_id):\n",
    "\n",
    "        if not detection_outputs.size :\n",
    "            return detection_outputs\n",
    "\n",
    "        processed_detections = self._pre_process(detection_outputs)\n",
    "        tracked_objects = self.tracker.update(processed_detections, frame_id = frame_id)\n",
    "        processed_tracked = self._post_process(tracked_objects)\n",
    "        return processed_tracked\n",
    "\n",
    "    def _pre_process(self,detection_outputs : np.ndarray):\n",
    "        return detection_outputs\n",
    "\n",
    "    def _post_process(self, tracked_objects : np.ndarray):\n",
    "\n",
    "        if tracked_objects.size :\n",
    "            if tracked_objects.ndim == 1:\n",
    "                tracked_objects = np.expand_dims(tracked_objects, 0)\n",
    "\n",
    "        return tracked_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_distance(obj1, obj2):\n",
    "    # Get the bounding boxes from the Metadata of each TrackedObject\n",
    "    bbox1 = obj1.metadata.bbox\n",
    "    bbox2 = obj2.metadata.bbox\n",
    "\n",
    "    # Calculate the Euclidean distance between the centers of the bounding boxes\n",
    "    center1 = ((bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2)\n",
    "    center2 = ((bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2)\n",
    "    distance = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "# TODO : discard by zone\n",
    "def select_by_category(obj1, obj2):\n",
    "    # Compare the categories of the two objects\n",
    "    return 1 if obj1.category == obj2.category else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence in SEQUENCES :\n",
    "    frame_path = get_sequence_frames(sequence)\n",
    "    test_sequence = Sequence(frame_path)\n",
    "    test_sequence\n",
    "    frame_id = 0\n",
    "    BaseTrack._count = 0\n",
    "\n",
    "        # Define the codec using VideoWriter_fourcc() and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'avc1')  # or use 'x264'\n",
    "    out = cv2.VideoWriter(f'{sequence}.mp4', fourcc, 20.0, (2560, 1440))  # adjust the frame size (640, 480) as per your needs\n",
    "\n",
    "\n",
    "    detection_handler = DetectionHandler(image_shape=[2560, 1440])\n",
    "    tracking_handler = TrackingHandler(tracker=BYTETracker(track_thresh= 0.3, track_buffer = 5, match_thresh = 0.85, frame_rate= 30))\n",
    "    reid_processor = ReidProcessor(filter_confidence_threshold=0.1,\n",
    "                                    filter_time_threshold=5,\n",
    "                                    cost_function=bounding_box_distance,\n",
    "                                    #cost_function_threshold=500, # max cost to rematch 2 objects\n",
    "                                    selection_function=select_by_category,\n",
    "                                    max_attempt_to_match=5,\n",
    "                                    max_frames_to_rematch=500)\n",
    "\n",
    "    for frame, detection in tqdm(test_sequence):\n",
    "        frame = np.array(frame)\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "        processed_detections = detection_handler.process(detection)\n",
    "        processed_tracked = tracking_handler.update(processed_detections, frame_id)\n",
    "        reid_results = reid_processor.update(processed_tracked, frame_id)\n",
    "\n",
    "        if len(reid_results) > 0:\n",
    "            for res in reid_results:\n",
    "                object_id = int(res[OUTPUT_POSITIONS[\"object_id\"]])\n",
    "                bbox = list(map(int, res[OUTPUT_POSITIONS[\"bbox\"]]))\n",
    "                class_id = int(res[OUTPUT_POSITIONS[\"category\"]])\n",
    "                tracker_id = int(res[OUTPUT_POSITIONS[\"tracker_id\"]])\n",
    "                mean_confidence = float(res[OUTPUT_POSITIONS[\"mean_confidence\"]])\n",
    "                #mean_confidence_per_object[object_id].append((frame_id, mean_confidence))\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                color = (0, 0, 255) if class_id  else (0, 255, 0)  # green for class 0, red for class 1\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{object_id} ({tracker_id}) : {round(mean_confidence,2)}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Write the frame to the video file\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "    print(sequence, len(reid_processor.seen_objects),reid_processor.nb_corrections)\n",
    "    print(reid_processor.seen_objects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track-reid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7fd834062a85a1fb9d4482d7456bec56e0ff99e4dd054f5e10ff6e3cdc923c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
