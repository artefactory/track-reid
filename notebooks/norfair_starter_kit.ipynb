{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value proposition of norfair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norfair is a customizable lightweight Python library for real-time multi-object tracking.\n",
    "Using Norfair, you can add tracking capabilities to any detector with just a few lines of code.\n",
    "\n",
    "It means you won't need a SOTA Tracker you can use a basic Tracker with a Kalmann Filter and add the custom logic you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "\n",
    "from lib.norfair_helper.utils import yolo_to_norfair_detection\n",
    "from lib.sequence import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from norfair import Tracker, draw_boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test this code on your detection and frames you can use the following code if you structure the data as follows:\n",
    "\n",
    "```\n",
    "data/\n",
    "   ├── detection/\n",
    "   │   └── sequence_1/\n",
    "   │       └── detections_1.txt\n",
    "   └── frames/\n",
    "       └── sequence_1/\n",
    "           └── frame_1.jpg\n",
    "```\n",
    "\n",
    "Where the detections.txt file is in the following format scaled between 0 and 1:\n",
    "\n",
    "```\n",
    "class_id x_center y_center width height confidence\n",
    "```\n",
    "\n",
    "If this is not the case, you'll need to adapt this code to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "DETECTION_PATH = f\"{DATA_PATH}/detections\"\n",
    "FRAME_PATH = f\"{DATA_PATH}/frames\"\n",
    "VIDEO_OUTPUT_PATH = \"private\"\n",
    "\n",
    "SEQUENCES = os.listdir(FRAME_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_frames(sequence):\n",
    "    frames = os.listdir(f\"{FRAME_PATH}/{sequence}\")\n",
    "    frames = [os.path.join(f\"{FRAME_PATH}/{sequence}\", frame) for frame in frames]\n",
    "    frames.sort()\n",
    "    return frames\n",
    "\n",
    "def get_sequence_detections(sequence):\n",
    "    detections = os.listdir(f\"{DETECTION_PATH}/{sequence}\")\n",
    "    detections = [os.path.join(f\"{DETECTION_PATH}/{sequence}\", detection) for detection in detections]\n",
    "    detections.sort()\n",
    "    return detections\n",
    "\n",
    "frame_path = get_sequence_frames(SEQUENCES[0])\n",
    "detection_path = get_sequence_detections(SEQUENCES[0])\n",
    "test_sequence = Sequence(frame_path, detection_path)\n",
    "test_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage of Norfair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracker\n",
    "\n",
    "Norfair tracker object is the customizable object that will track detections.\n",
    "Norfair expects a distance function that will serve as a metric to match objects between each detection. You can create your own distance metric or use one of the built-in ones such as euclidian distance, iou or many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a tracker with the distance function\n",
    "basic_tracker = Tracker(\n",
    "    distance_function=\"mean_euclidean\",\n",
    "    distance_threshold=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "FRAME_SIZE = (2560, 1440)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Changed codec to 'mp4v' for compatibility with Mac\n",
    "out = cv2.VideoWriter(f'{VIDEO_OUTPUT_PATH}/basic_tracking.mp4', fourcc, 20.0, FRAME_SIZE) # Changed file extension to .mp4\n",
    "\n",
    "for frame, detection in test_sequence:\n",
    "    detections_list = yolo_to_norfair_detection(detection, frame.size)\n",
    "    tracked_objects = basic_tracker.update(detections=detections_list)\n",
    "    frame_detected = draw_boxes(np.array(frame), tracked_objects, draw_ids=True, color=\"by_label\")\n",
    "    frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_BGR2RGB)\n",
    "    out.write(frame_detected)\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reid_distance_advanced(new_object, unmatched_object):\n",
    "    return 0 # ALWAYS MATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_tracker = Tracker(\n",
    "    distance_function=\"sqeuclidean\",\n",
    "    distance_threshold=350, # Higher value means objects further away will be matched\n",
    "    initialization_delay=15, # Wait 15 frames before an object is starts to be tracked\n",
    "    hit_counter_max=12, # Inertia, higher values means an object will take time to enter in reid phase\n",
    "    reid_distance_function=reid_distance_advanced, # function to decide on which metric to reid\n",
    "    reid_distance_threshold=0.5, # If the distance is below 0.5 the object is matched\n",
    "    reid_hit_counter_max=200, # inertia, higher values means an object will enter reid phase longer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "FRAME_SIZE = (2560, 1440)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Changed codec to 'mp4v' for compatibility with Mac\n",
    "out = cv2.VideoWriter(f'{VIDEO_OUTPUT_PATH}/advance_tracking.mp4', fourcc, 20.0, FRAME_SIZE) # Changed file extension to .mp4\n",
    "\n",
    "for frame, detection in test_sequence:\n",
    "    detections_list = yolo_to_norfair_detection(detection, frame.size)\n",
    "    tracked_objects = advanced_tracker.update(detections=detections_list)\n",
    "    frame_detected = draw_boxes(np.array(frame), tracked_objects, draw_ids=True, color=\"by_label\")\n",
    "    frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_BGR2RGB)\n",
    "    out.write(frame_detected)\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track-reid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
