{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from bytetracker import BYTETracker\n",
    "from bytetracker.basetrack import BaseTrack\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.bbox.utils import rescale_bbox, xy_center_to_xyxy\n",
    "from lib.sequence import Sequence\n",
    "from trackreid.args.reid_args import OUTPUT_POSITIONS\n",
    "from trackreid.reid_processor import ReidProcessor\n",
    "\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline data can be found in `gs://data-track-reid/predictions/baseline`. You can copy them in `../data/predictions/` using the following commands (in a terminal at the root of the project):\n",
    "\n",
    "```bash\n",
    "mkdir -p ./data/predictions/\n",
    "gsutil -m cp -r gs://data-track-reid/predictions/baseline ./data/predictions/\n",
    "```\n",
    "\n",
    "Then you can reoganize the data using the following : \n",
    "```bash \n",
    "find ./data/predictions/baseline -mindepth 2 -type f -name \"*.txt\" -exec sh -c 'mv \"$0\" \"${0%/*/*}/$(basename \"${0%/*}\").txt\"' {} \\; && find ./data/predictions/baseline -mindepth 1 -type d -empty -delete\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real life data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "DETECTION_PATH = f\"{DATA_PATH}/detections\"\n",
    "FRAME_PATH = f\"{DATA_PATH}/frames\"\n",
    "PREDICTIONS_PATH = f\"{DATA_PATH}/predictions\"\n",
    "VIDEO_OUTPUT_PATH = \"private\"\n",
    "\n",
    "SEQUENCES = os.listdir(DETECTION_PATH)\n",
    "GENERATE_VIDEOS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_frames(sequence):\n",
    "    frames = os.listdir(f\"{FRAME_PATH}/{sequence}\")\n",
    "    frames = [os.path.join(f\"{FRAME_PATH}/{sequence}\", frame) for frame in frames]\n",
    "    frames.sort()\n",
    "    return frames\n",
    "\n",
    "def get_sequence_detections(sequence):\n",
    "    detections = os.listdir(f\"{DETECTION_PATH}/{sequence}\")\n",
    "    detections = [os.path.join(f\"{DETECTION_PATH}/{sequence}\", detection) for detection in detections]\n",
    "    detections.sort()\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHandler():\n",
    "    def __init__(self, image_shape) -> None:\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "    def process(self, detection_output):\n",
    "        if detection_output.size:\n",
    "            if detection_output.ndim == 1:\n",
    "                detection_output = np.expand_dims(detection_output, 0)\n",
    "\n",
    "            processed_detection = np.zeros(detection_output.shape)\n",
    "\n",
    "            for idx, detection in enumerate(detection_output):\n",
    "                clss = detection[0]\n",
    "                conf = detection[5]\n",
    "                bbox = detection[1:5]\n",
    "                xyxy_bbox = xy_center_to_xyxy(bbox)\n",
    "                rescaled_bbox = rescale_bbox(xyxy_bbox,self.image_shape)\n",
    "                processed_detection[idx,:4] = rescaled_bbox\n",
    "                processed_detection[idx,4] = conf\n",
    "                processed_detection[idx,5] = clss\n",
    "\n",
    "            return processed_detection\n",
    "        else:\n",
    "            return detection_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingHandler():\n",
    "    def __init__(self, tracker) -> None:\n",
    "        self.tracker = tracker\n",
    "\n",
    "    def update(self, detection_outputs, frame_id):\n",
    "\n",
    "        if not detection_outputs.size :\n",
    "            return detection_outputs\n",
    "\n",
    "        processed_detections = self._pre_process(detection_outputs)\n",
    "        tracked_objects = self.tracker.update(processed_detections, frame_id = frame_id)\n",
    "        processed_tracked = self._post_process(tracked_objects)\n",
    "        return processed_tracked\n",
    "\n",
    "    def _pre_process(self,detection_outputs : np.ndarray):\n",
    "        return detection_outputs\n",
    "\n",
    "    def _post_process(self, tracked_objects : np.ndarray):\n",
    "\n",
    "        if tracked_objects.size :\n",
    "            if tracked_objects.ndim == 1:\n",
    "                tracked_objects = np.expand_dims(tracked_objects, 0)\n",
    "\n",
    "        return tracked_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_distance(obj1, obj2):\n",
    "    # Get the bounding boxes from the Metadata of each TrackedObject\n",
    "    bbox1 = obj1.metadata.bbox\n",
    "    bbox2 = obj2.metadata.bbox\n",
    "\n",
    "    # Calculate the Euclidean distance between the centers of the bounding boxes\n",
    "    center1 = ((bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2)\n",
    "    center2 = ((bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2)\n",
    "    distance = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "# TODO : discard by zone\n",
    "def select_by_category(obj1, obj2):\n",
    "    # Compare the categories of the two objects\n",
    "    return 1 if obj1.category == obj2.category else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "print(timestamp)\n",
    "folder_save = os.path.join(PREDICTIONS_PATH,timestamp)\n",
    "os.makedirs(folder_save, exist_ok=True)\n",
    "GENERATE_VIDEOS = False\n",
    "for sequence in tqdm(SEQUENCES) :\n",
    "    frame_path = get_sequence_frames(sequence)\n",
    "    test_sequence = Sequence(frame_path)\n",
    "    frame_id = 0\n",
    "    BaseTrack._count = 0\n",
    "    from datetime import datetime\n",
    "\n",
    "    file_path = os.path.join(folder_save,sequence) + '.txt'\n",
    "    video_path = os.path.join(folder_save,sequence) + '.mp4'\n",
    "\n",
    "    if GENERATE_VIDEOS:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'avc1')  # or use 'x264'\n",
    "        out = cv2.VideoWriter(video_path, fourcc, 20.0, (2560, 1440))  # adjust the frame size (640, 480) as per your needs\n",
    "\n",
    "    detection_handler = DetectionHandler(image_shape=[2560, 1440])\n",
    "    tracking_handler = TrackingHandler(tracker=BYTETracker(track_thresh= 0.3, track_buffer = 5, match_thresh = 0.85, frame_rate= 30))\n",
    "    reid_processor = ReidProcessor(filter_confidence_threshold=0.1,\n",
    "                                    filter_time_threshold=5,\n",
    "                                    cost_function=bounding_box_distance,\n",
    "                                    cost_function_threshold=5000, # max cost to rematch 2 objects\n",
    "                                    selection_function=select_by_category,\n",
    "                                    max_attempt_to_match=5,\n",
    "                                    max_frames_to_rematch=500,\n",
    "                                    save_to_txt=True,\n",
    "                                    file_path=file_path)\n",
    "\n",
    "    for frame, detection in test_sequence:\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "        processed_detections = detection_handler.process(detection)\n",
    "        processed_tracked = tracking_handler.update(processed_detections, frame_id)\n",
    "        reid_results = reid_processor.update(processed_tracked, frame_id)\n",
    "\n",
    "        if GENERATE_VIDEOS and len(reid_results) > 0:\n",
    "            frame = np.array(frame)\n",
    "            for res in reid_results:\n",
    "                object_id = int(res[OUTPUT_POSITIONS[\"object_id\"]])\n",
    "                bbox = list(map(int, res[OUTPUT_POSITIONS[\"bbox\"]]))\n",
    "                class_id = int(res[OUTPUT_POSITIONS[\"category\"]])\n",
    "                tracker_id = int(res[OUTPUT_POSITIONS[\"tracker_id\"]])\n",
    "                mean_confidence = float(res[OUTPUT_POSITIONS[\"mean_confidence\"]])\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                color = (0, 0, 255) if class_id  else (0, 255, 0)  # green for class 0, red for class 1\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{object_id} ({tracker_id}) : {round(mean_confidence,2)}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "        if GENERATE_VIDEOS:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            out.write(frame)\n",
    "\n",
    "    if GENERATE_VIDEOS :\n",
    "        out.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_occurrences(file_path, case):\n",
    "    object_counts = defaultdict(int)\n",
    "    class_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.split()\n",
    "\n",
    "            if case != 'baseline':\n",
    "                object_id = int(data[1])\n",
    "                category = int(data[2])\n",
    "            else:\n",
    "                object_id = int(data[1])\n",
    "                category = int(data[-1])\n",
    "\n",
    "            object_counts[object_id] += 1\n",
    "            class_counts[object_id][category] += 1\n",
    "\n",
    "    return object_counts, class_counts\n",
    "\n",
    "def filter_counts(object_counts, class_counts, min_occurrences=10):\n",
    "    filtered_objects = {}\n",
    "\n",
    "    for object_id, count in object_counts.items():\n",
    "        if count > min_occurrences and class_counts[object_id][0] > class_counts[object_id][1]:\n",
    "            filtered_objects[object_id] = count\n",
    "\n",
    "    return filtered_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS = f\"../data/predictions/{timestamp}\"\n",
    "\n",
    "for sequence in SEQUENCES:\n",
    "    print(\"-\"*50)\n",
    "    print(sequence)\n",
    "\n",
    "    for case in [\"baseline\", timestamp]:\n",
    "        object_counts, class_counts = count_occurrences(f'../data/predictions/{case}/{sequence}.txt', case=case)\n",
    "        filtered_objects = filter_counts(object_counts, class_counts)\n",
    "\n",
    "        print(case)\n",
    "        print(filtered_objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track-reid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7fd834062a85a1fb9d4482d7456bec56e0ff99e4dd054f5e10ff6e3cdc923c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
