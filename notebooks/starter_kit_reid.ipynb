{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trackreid.reid_processor import ReidProcessor\n",
    "import cv2\n",
    "from tqdm import tqdm \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real life data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lib.sequence import Sequence\n",
    "from bytetracker import BYTETracker\n",
    "from lib.bbox.utils import xy_center_to_xyxy, rescale_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "DETECTION_PATH = f\"{DATA_PATH}/detections\"\n",
    "FRAME_PATH = f\"{DATA_PATH}/frames\"\n",
    "VIDEO_OUTPUT_PATH = \"private\"\n",
    "\n",
    "SEQUENCES = os.listdir(FRAME_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_frames(sequence):\n",
    "    frames = os.listdir(f\"{FRAME_PATH}/{sequence}\")\n",
    "    frames = [os.path.join(f\"{FRAME_PATH}/{sequence}\", frame) for frame in frames]\n",
    "    frames.sort()\n",
    "    return frames\n",
    "\n",
    "def get_sequence_detections(sequence):\n",
    "    detections = os.listdir(f\"{DETECTION_PATH}/{sequence}\")\n",
    "    detections = [os.path.join(f\"{DETECTION_PATH}/{sequence}\", detection) for detection in detections]\n",
    "    detections.sort()\n",
    "    return detections\n",
    "\n",
    "frame_path = get_sequence_frames(SEQUENCES[2])\n",
    "test_sequence = Sequence(frame_path)\n",
    "test_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHandler():\n",
    "    def __init__(self, image_shape) -> None:\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "    def process(self, detection_output):\n",
    "        if detection_output.size:\n",
    "            if detection_output.ndim == 1:\n",
    "                detection_output = np.expand_dims(detection_output, 0)\n",
    "\n",
    "            processed_detection = np.zeros(detection_output.shape)\n",
    "\n",
    "            for idx, detection in enumerate(detection_output):\n",
    "                clss = detection[0]\n",
    "                conf = detection[5]\n",
    "                bbox = detection[1:5]\n",
    "                xyxy_bbox = xy_center_to_xyxy(bbox)\n",
    "                rescaled_bbox = rescale_bbox(xyxy_bbox,self.image_shape)\n",
    "                processed_detection[idx,:4] = rescaled_bbox\n",
    "                processed_detection[idx,4] = conf\n",
    "                processed_detection[idx,5] = clss\n",
    "                \n",
    "\n",
    "            return processed_detection\n",
    "        else:\n",
    "            return detection_output\n",
    "            \n",
    "detection_handler = DetectionHandler(image_shape=[2560, 1440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingHandler():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def process(self, tracked_objects : np.ndarray, frame_id):\n",
    "\n",
    "        if tracked_objects.size :\n",
    "            if tracked_objects.ndim == 1:\n",
    "                tracked_objects = np.expand_dims(tracked_objects, 0)\n",
    "\n",
    "            processed_tracked = np.zeros((len(tracked_objects), 8))\n",
    "            processed_tracked[:,0] = frame_id\n",
    "            processed_tracked[:,1] = tracked_objects[:,4]\n",
    "            processed_tracked[:,2] = tracked_objects[:,5]\n",
    "            processed_tracked[:,3:7] = tracked_objects[:,:4]\n",
    "            processed_tracked[:,7] = tracked_objects[:,6]\n",
    "        \n",
    "            return processed_tracked\n",
    "        else:\n",
    "            return tracked_objects\n",
    "\n",
    "        \n",
    "tracking_handler = TrackingHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_distance(obj1, obj2):\n",
    "    # Get the bounding boxes from the Metadata of each TrackedObject\n",
    "    bbox1 = obj1.metadata.bbox\n",
    "    bbox2 = obj2.metadata.bbox\n",
    "\n",
    "    # Calculate the Euclidean distance between the centers of the bounding boxes\n",
    "    center1 = ((bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2)\n",
    "    center2 = ((bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2)\n",
    "    distance = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "# TODO : discard by zone\n",
    "def select_by_category(obj1, obj2):\n",
    "    # Compare the categories of the two objects\n",
    "    return 1 if obj1.category == obj2.category else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 0\n",
    "from bytetracker.basetrack import BaseTrack\n",
    "BaseTrack._count = 0\n",
    "\n",
    "# Define the codec using VideoWriter_fourcc() and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'avc1')  # or use 'x264'\n",
    "out = cv2.VideoWriter('output_corrected.mp4', fourcc, 20.0, (2560, 1440))  # adjust the frame size (640, 480) as per your needs\n",
    "\n",
    "\n",
    "tracker = BYTETracker(track_thresh= 0.3, track_buffer = 5, match_thresh = 0.85, frame_rate= 30)\n",
    "reid_processor = ReidProcessor(filter_confidence_threshold=0.1, \n",
    "                          filter_time_threshold=0,\n",
    "                          cost_function=bounding_box_distance,\n",
    "                          selection_function=select_by_category,\n",
    "                          max_attempt_to_rematch=1,\n",
    "                          max_frames_to_rematch=100)\n",
    "\n",
    "\n",
    "\n",
    "for frame, detection in tqdm(test_sequence):\n",
    "    frame = np.array(frame)\n",
    "\n",
    "    processed_detections = detection_handler.process(detection)\n",
    "    if processed_detections.size:\n",
    "        frame_id += 1\n",
    "        tracked_objects = tracker.update(dets=processed_detections,_=None)\n",
    "        processed_tracked = tracking_handler.process(tracked_objects, frame_id)\n",
    "        if processed_tracked.size:\n",
    "            result = reid_processor.update(processed_tracked, frame_id)\n",
    "        else:\n",
    "            result = []\n",
    "    else:\n",
    "        result = []\n",
    "\n",
    "    stop = False\n",
    "\n",
    "    if result:\n",
    "        for res in result:\n",
    "            frame_id, object_id, class_id, x1, y1, x2, y2, confidence_score = res\n",
    "            frame_id, object_id, class_id, x1, y1, x2, y2 = int(frame_id), int(object_id), int(class_id), int(x1), int(y1), int(x2), int(y2)\n",
    "            color = (0, 255, 0) if class_id == 0.0 else (0, 0, 255)  # green for class 0, red for class 1\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, str(object_id), (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "            if object_id == 34 :\n",
    "                break\n",
    "                stop = True\n",
    "    \n",
    "    if stop :\n",
    "        break\n",
    "\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Write the frame to the video file\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_processor.all_tracked_objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track-reid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7fd834062a85a1fb9d4482d7456bec56e0ff99e4dd054f5e10ff6e3cdc923c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
